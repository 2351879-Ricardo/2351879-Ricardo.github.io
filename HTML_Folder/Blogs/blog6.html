<section class="section-post">
  <header>
    <button class="collapse" onclick="ToggleCollapseView(this)">
      <h1>Justice in Software Development</h1>
      <address>Ricardo Costa-Tr√©</address>
      <time pubdate datetime="2022-06-10" title="June 10th, 2022">
        10 June 2022
      </time>
    </button>
  </header>

  <article class="collapse-content">
    <h2>Justice in Software Development</h2>
    <p>
      With software making up a huge chunk of our lives, stemming from our work,
      entertainment, and general news outlet, it is important to make sure that
      the production and usage of this said software are properly implemented.
      While this sentence is extremely broad and can be interpreted in many
      ways, it has relevance to the creation and usage of software in today's
      age, specifically regarding ethical use.
    </p>
    <p>
      Looking at the development of software in many fields, it is hard to not
      find a situation in which ethical standards were breached. Just look at
      Facebook, and all the dilemmas they have been through in the past 10
      years. Surely they are bad people! They are extorting people and have been
      the medium for events such as terrorist attacks!
    </p>
    <p>Well, maybe not exactly?</p>
    <p>
      Now before people think I am defending Facebook, I am not. I personally
      don't agree with a lot of their choices - which mainly leads me to be very
      inactive on their platform. However, does that make them bad people?
    </p>
    <h3>Anti-Rohingya Violence Incident (Facebook)</h3>
    <p>Again with Facebook?</p>
    <p>
      Well yes, but it will change. This is just the spark used to create the
      fire. I feel this incident has one underlying point that I want to mention
      before going down the rabbit hole of what this post will be.
    </p>
    <p>So, the Anti-Rohingya Incident.</p>
    <p>
      In short, terrorist attacks were planned and communicated by people using
      Facebook. People blamed Facebook for not defusing the situation and
      letting it happen, while Facebook argued they were just the medium and
      really can't be held liable.
    </p>
    <p>
      A very gross oversimplification, but it highlights enough critical points
      to discuss what I had in mind.
    </p>
    <p>Oh boy, here we go.</p>
    <p>...</p>
    <p>Yes and No</p>
    <p>...</p>
    <p>Maybe, who knows?</p>
    <p>...</p>
    <p>I have no idea.</p>
    <p>
      But you might be screaming at your screens, "But they were a medium
      through which a terrorist attack and violence was conducted. They could
      have stopped."
    </p>
    <p>
      Could they have stopped it? Yeah very likely, if they monitored the data,
      read through the messages, and dealt with it accordingly. Yeah sure, they
      could have.
    </p>
    <p>But then, they would have been breaking another ethical issue.</p>
    <p>
      According to Facebook's terms and service agreements, they had started to
      users that they would not read the actual text. This was, as a matter of
      fact, the same agreement that Facebook had used as a validation for their
      social experiment in 2012.
    </p>
    <p>
      Now before we continue, I do want to state that I am not using this as an
      excuse to ignore what Facebook did in 2012. What they did was extremely
      wrong in my opinion. What they were conducting was social manipulation on
      real live humans who did not know they were a part of AND did not concept
      of the experiment.
    </p>
    <p>
      However, this can't excuse the underlying issue of the double standards
      expected by users.
    </p>
    <p>
      Users expect their data to be kept private and not read, but then expect
      it to be filtered for terrorist content.
    </p>
    <p>But AI, right? Humans don't have to read it.</p>
    <p>Yikes! Another can of worms.</p>
    <p>
      Besides the fact that using AI would (in my opinion) still be counted as
      filtering through information and my information is no longer private, AI
      is still not a valid option... Kind of.
    </p>
    <h3>Google Photos Image Recognition</h3>
    <p>
      Now, this is an extremely uncomfortable topic for many people, so let's
      just get in and out.
    </p>
    <p>
      A dark-skinned individual was identified as a gorilla by the image
      recognition software Google.
    </p>
    <p>
      Now while I am near certain that this was not Google's intention (and I
      hope it was not), the AI screwed up. Big time. Though it is hard to blame
      the AI. After all, it was just machine learning through data provided by
      humans. While the data may have not meant to be portrayed like that, the
      factor of human bias can and will be picked up by machine learning AI
      further down the chain.
    </p>
    <p>
      So if the AI is flawed, should we be using it? Would it not be better to
      have it manually done by people to prevent these errors?
    </p>
    <p>Not quite...</p>
    <h3>Automation vs Manual Labor</h3>
    <p>
      It has been seen that many ethical dilemmas have been the result of a
      software developer trying to automate a process. Examples of such cases
      can be seen with the aforementioned Google Images Recognition, but also
      elsewhere such as the automation of the 52 training courses with Zenefits.
    </p>
    <p>
      Automation can cause ethical dilemmas, but what can we do about it? We
      can't just get rid of automation. It is most likely the thing that keeps
      modern society pushing forward but also keeping it from collapsing. The
      butterfly effect on all industries will be horrific, likely to create a
      dark age. Not convinced? Let's take an example.
    </p>
    <p>
      The Banking Industry. Alright, everything is already chaotic. EFTs would
      firstly no longer exist. If they did, it would also be an extremely
      painful process. Do you want to send money? Okay, please provide your
      password, proof that it is you (preferably with an ID or Passport), and
      give information about the person's account you want to deposit to. Now
      await human verification for all of those details.
    </p>
    <p>That is a lot of time.</p>
    <p>But it's fine, you are now in. The rest should be easy.</p>
    <p>
      Alright, now time to see how much you want to deposit, verify it, make
      sure either of your accounts isn't blacklisted, and check if you have
      funds.
    </p>
    <p>Now await human verification again.</p>
    <p>But wait, you want to deposit to a person with a DIFFERENT bank.</p>
    <p>
      Okay, time for your bank to ring up the other bank and then proceed to
      give all the information you provided... and STILL await verification for
      that.
    </p>
    <p>This example can go on and on, and this is just for a simple EFT.</p>
    <p>
      Okay, so we can't get rid of automation. So what can we do? Well, Bryan
      Cantrill spoke in his Craft Conf in 2019 that humans should be put back
      into the loop. This way information can be verified again and checked if
      it is ethical, correct, and appropriate. A brilliant idea, but I do have a
      small issue with that.
    </p>
    <p>
      When do we add humans back into the loop? How much should they be
      verifying? How frequently will these checks need to take place?
    </p>
    <p>
      It is also difficult to keep swapping from AI to human back to AI and so
      forth, as the reinput back into the machine will leave more
      vulnerabilities for unintended bias to leak through.
    </p>
    <p>
      Once again, you can't have humans do this all manually. Remember the
      people who manually get rid of content on YouTube? Remember how that went?
    </p>
    <h3>Conclusion</h3>
    <p>
      So what is it we exactly do? How do we know how to act, what to deliver to
      the public, what is right, and what is wrong?
    </p>
    <p>
      It all starts to get a little bit blurred. Exceptions become apparent and
      then systems become flawed. The biggest frustration among engineers is
      that ethics is not simple mathematics. There is no just right or just
      wrong, there always seem to be exceptions, exceptions of exceptions,
      Exceptions that are exceptions to an exception, and so forth.
    </p>
    <p>
      The truth is ethics will never be as easy as right or wrong, on or off, or
      any binary behavior. It is a language of dependencies that blur lines and
      creates an answer that is neither on nor off. I hate saying this because
      it annoys me there is no correct or easy solution - it is always relative
      to the situation.
    </p>
    <p>
      Hence, I believe the people at ACM have the correct idea. Businesses and
      Software Developers should focus on giving to society in a way that
      benefits it. If there stems from a problem that wasn't intended, the idea
      of helping to the best of your ability is always good. The only annoyance
      I have with this is that it never seems that the users have any
      consequences and there is a mentality of the user is always right in a lot
      of practices.
    </p>
    <p>But how do I know what is the relative solution to my situation?</p>
    <p>
      I don't know. I can't tell you. You have to question it, investigate it
      and understand it. It isn't as simple as an if-else statement.
    </p>
    <p>After all, how long is a piece of string?</p>
    <section class="references">
      <h3>References:</h3>
      <cite>
        <ul>
          <li>
            Association for Computing Machinery. (2018, June 22). ACM Code of
            Ethics and Professional Conduct. Retrieved from Association for
            Computing Machinery:
            <a href="https://www.acm.org/code-of-ethics"
              >https://www.acm.org/code-of-ethics</a
            >
          </li>
          <li>
            CraftHub Events. (2019, May 17). Bryan Cantrill: Andreessen's
            Corollary: Ethical Dilemmas in Software Engineering - Craft Conf
            2019. Retrieved from YouTube:
            <a href="https://www.youtube.com/watch?v=0wtvQZijPzg"
              >https://www.youtube.com/watch?v=0wtvQZijPzg</a
            >
          </li>
        </ul>
      </cite>
    </section>
  </article>
</section>
